{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9faf1ec",
   "metadata": {},
   "source": [
    "# Tokenizer Demo\n",
    "This notebook demonstrates tokenization using two popular libraries:\n",
    "- **Hugging Face Transformers** – for BERT‑style tokenizers\n",
    "- **tiktoken** – OpenAI's fast tokeniser used by GPT models\n",
    "\n",
    "## Installation\n",
    "You need to install the following Python packages before running the examples:\n",
    "```bash\n",
    "pip install transformers tiktoken\n",
    "```\n",
    "The command above works on most platforms (Linux, macOS, Windows).\n",
    "\n",
    "### Detailed tiktoken installation notes\n",
    "* **Python version**: tiktoken requires Python >= 3.8.\n",
    "* **Binary wheels**: For Linux/macOS, pip will download pre‑compiled wheels (manylinux). No compiler is needed.\n",
    "* **Building from source**: If a wheel is not available for your platform, pip will attempt to build from source. This requires a C compiler (e.g., `gcc` on Linux, `clang` on macOS) and `rustc` because tiktoken includes Rust extensions. Install Rust via `curl https://sh.rustup.rs -sSf | sh` if needed.\n",
    "* **Conda users**: You can also install via conda‑forge: `conda install -c conda-forge tiktoken`.\n",
    "* **Optional dependencies**: No additional system libraries are required for the basic encoder. If you plan to use the `tiktoken` tokenizer with OpenAI's `gpt‑3.5‑turbo` or `gpt‑4` models, ensure you have internet access for the model‑specific encodings (they are bundled).\n",
    "* **Verification**: After installation, you can run `python -c \"import tiktoken, sys; print(tiktoken.__version__)\"` to confirm it works.\n",
    "\n",
    "You can also install the packages directly from this notebook using the magic command below (run the cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "149aaeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (4.57.6)\n",
      "Requirement already satisfied: tiktoken in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (0.12.0)\n",
      "Requirement already satisfied: filelock in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/dipak/dipak-workspace/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580bc5e8",
   "metadata": {},
   "source": [
    "## Example 1: Hugging Face Transformers tokenizer\n",
    "We load the `bert-base-uncased` tokenizer and tokenize a short sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6922a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformers tokens: ['hello', ',', 'world', '!', 'this', 'is', 'a', 'token', '##izer', 'demo', '.']\n",
      "Encoded ids: [7592, 1010, 2088, 999, 2023, 2003, 1037, 19204, 17629, 9703, 1012]\n",
      "Decoded text: hello, world! this is a tokenizer demo.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "text = \"Hello, world! This is a tokenizer demo.\"\n",
    "print('Transformers tokens:', tokenizer.tokenize(text))\n",
    "# Encode to ids and decode back\n",
    "ids = tokenizer.encode(text, add_special_tokens=False)\n",
    "print('Encoded ids:', ids)\n",
    "decoded = tokenizer.decode(ids)\n",
    "print('Decoded text:', decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2f1b8a",
   "metadata": {},
   "source": [
    "## Example 2: tiktoken\n",
    "tiktoken provides fast tokenisation for OpenAI models.\n",
    "We use the `cl100k_base` encoding (used by gpt‑3.5‑turbo and gpt‑4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea691837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiktoken tokens: [9906, 11, 1917, 0, 1115, 374, 264, 47058, 17074, 13]\n",
      "Number of tokens: 10\n",
      "Decoded with tiktoken: Hello, world! This is a tokenizer demo.\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "enc = tiktoken.get_encoding('cl100k_base')\n",
    "print('tiktoken tokens:', enc.encode(text))\n",
    "print('Number of tokens:', len(enc.encode(text)))\n",
    "# Decode back to string\n",
    "decoded_tiktoken = enc.decode(enc.encode(text))\n",
    "print('Decoded with tiktoken:', decoded_tiktoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f6a78-7eac-4fa8-915f-2fba1c1d8c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
