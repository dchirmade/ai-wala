{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f9faf1ec",
            "metadata": {},
            "source": [
                "# Tokenizer Demo\n",
                "This notebook demonstrates tokenization using two popular libraries:\n",
                "- **Hugging Face Transformers** – for BERT‑style tokenizers\n",
                "- **tiktoken** – OpenAI's fast tokeniser used by GPT models\n",
                "\n",
                "## Installation\n",
                "You need to install the following Python packages before running the examples:\n",
                "```bash\n",
                "pip install transformers tiktoken\n",
                "```\n",
                "The command above works on most platforms (Linux, macOS, Windows).\n",
                "\n",
                "### Detailed tiktoken installation notes\n",
                "* **Python version**: tiktoken requires Python >= 3.8.\n",
                "* **Binary wheels**: For Linux/macOS, pip will download pre‑compiled wheels (manylinux). No compiler is needed.\n",
                "* **Building from source**: If a wheel is not available for your platform, pip will attempt to build from source. This requires a C compiler (e.g., `gcc` on Linux, `clang` on macOS) and `rustc` because tiktoken includes Rust extensions. Install Rust via `curl https://sh.rustup.rs -sSf | sh` if needed.\n",
                "* **Conda users**: You can also install via conda‑forge: `conda install -c conda-forge tiktoken`.\n",
                "* **Optional dependencies**: No additional system libraries are required for the basic encoder. If you plan to use the `tiktoken` tokenizer with OpenAI's `gpt‑3.5‑turbo` or `gpt‑4` models, ensure you have internet access for the model‑specific encodings (they are bundled).\n",
                "* **Verification**: After installation, you can run `python -c \"import tiktoken, sys; print(tiktoken.__version__)\"` to confirm it works.\n",
                "\n",
                "You can also install the packages directly from this notebook using the magic command below (run the cell)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "149aaeff",
            "metadata": {},
            "outputs": [],
            "source": [
                "%pip install transformers tiktoken"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "580bc5e8",
            "metadata": {},
            "source": [
                "## Example 1: Hugging Face Transformers tokenizer\n",
                "We load the `bert-base-uncased` tokenizer and tokenize a short sentence."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6922a801",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import AutoTokenizer\n",
                "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
                "text = \"Hello, world! This is a tokenizer demo.\"\n",
                "print('Transformers tokens:', tokenizer.tokenize(text))\n",
                "# Encode to ids and decode back\n",
                "ids = tokenizer.encode(text, add_special_tokens=False)\n",
                "print('Encoded ids:', ids)\n",
                "decoded = tokenizer.decode(ids)\n",
                "print('Decoded text:', decoded)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ee2f1b8a",
            "metadata": {},
            "source": [
                "## Example 2: tiktoken\n",
                "tiktoken provides fast tokenisation for OpenAI models.\n",
                "We use the `cl100k_base` encoding (used by gpt‑3.5‑turbo and gpt‑4)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ea691837",
            "metadata": {},
            "outputs": [],
            "source": [
                "import tiktoken\n",
                "enc = tiktoken.get_encoding('cl100k_base')\n",
                "print('tiktoken tokens:', enc.encode(text))\n",
                "print('Number of tokens:', len(enc.encode(text)))\n",
                "# Decode back to string\n",
                "decoded_tiktoken = enc.decode(enc.encode(text))\n",
                "print('Decoded with tiktoken:', decoded_tiktoken)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f19f6a78-7eac-4fa8-915f-2fba1c1d8c1a",
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}